---
title: 通过 AutoML 避免过度拟合和不均衡数据
titleSuffix: Azure Machine Learning
description: 通过 Azure 机器学习的自动化机器学习解决方案，识别和管理 ML 模型的常见错误。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: 8945a5766865f4df6175e7330d3bf9c947e1fa0d
ms.sourcegitcommit: 9caa850a2b26773e238f8ba6f4ca151c47260915
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 07/11/2021
ms.locfileid: "113600489"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>通过自动化机器学习防止过度拟合和不均衡数据

在生成机器学习模型时，过度拟合和不均衡数据是常见的错误。 默认情况下，Azure 机器学习的自动化机器学习提供图表和指标来帮助你识别这些风险，并实施最佳做法以帮助缓解这些风险。 

## <a name="identify-overfitting"></a>识别过度拟合

如果模型非常适应定型数据，则在机器学习中会发生过度拟合，因此无法准确预测不可见的测试数据。 换句话说，模型只是简单地记住了定型数据中的特定模式和噪音，但并不太灵活，无法预测实时数据。

请考虑以下已定型的模型及其相应的定型和测试准确度。

| 型号 | 训练准确度 | 测试准确度 |
|-------|----------------|---------------|
| A | 99.9% | 95% |
| B | 87% | 87% |
| C | 99.9% | 45% |

就模型 A 而言，存在一种常见的误解 - 如果不可见数据的测试准确度低于定型准确度，则该模型过度拟合。 但是，测试准确度应始终小于定型准确度，并且过度拟合和适度拟合的区别在于准确度低多少。 

在比较模型 A 与 B 时，模型 A 更好，因为该模型具有更高的测试准确度，尽管 95% 的测试准确度略低，但差异并不显著，无法说明存在过度拟合  。 不选择模型 **B** 的原因仅仅是训练和测试精度更为接近。

模型 C 代表了一个明显的过度拟合情况；定型准确度非常高，但测试准确度却并没有那么高。 这种分辨方式虽然较主观，但却是从对问题和数据的了解以及可接受的误差大小中得出的。

## <a name="prevent-overfitting"></a>防止过度拟合

在大多数严重情况下，过度拟合的模型将假定在定型过程中出现的功能值组合将始终生成与目标完全相同的输出。

防止过度拟合的最佳方式是遵循 ML 最佳做法，其中包括：

* 使用更多训练数据，并消除统计偏差
* 防止目标泄露
* 使用较少的特征
* **正则化和超参数优化**
* **模型复杂性限制**
* **交叉验证**

在自动化 ML 的上下文中，上面所述的前三项是 **你要实施的最佳做法**。 带粗体格式的后三项是自动化 ML 为了防止过度拟合而默认实施的最佳做法。 在除自动化 ML 以外的设置中，为了避免过度拟合模型，值得遵循所有六项最佳做法。

## <a name="best-practices-you-implement"></a>你要实施的最佳做法

### <a name="use-more-data"></a>使用更多数据

使用更多数据是防止过度拟合的最简单且最可行的方法，而且通常还能提高准确性，这是它的一个额外好处。 使用更多数据时，模型将更难以记住确切的模式，因此它被迫达成可以更灵活地适应更多条件的解决方案。 此外，必须识别 **统计偏差**，以确保训练数据不包含实时预测数据中不存在的隔离模式。 此问题可能很难解决，因为训练集和测试集之间可能不存在过度拟合，但与实时测试数据相比，可能又存在过度拟合。

### <a name="prevent-target-leakage"></a>防止目标泄漏

目标泄漏是一个类似的问题；在这种情况下，可能在训练/测试集之间看不到过度拟合，但在预测时却会出现过度拟合。 当你的模型在定型期间“作弊”，访问在预测时不应有的数据时，就会发生目标泄漏。 例如，如果你的问题是在星期一预测星期五的商品价格，但某个功能意外包含星期四的数据，这就是模型在预测时不会有的数据，因为它不能预知未来。 目标泄漏是一个很容易疏忽的错误，但问题的准确度异常高，则往往可以体现此错误。 如果你正在尝试预测股票价格，并且定型模型的准确度为 95%，则功能中可能存在目标泄漏。

### <a name="use-fewer-features"></a>使用较少的特征

删除特征也有助于避免过度拟合问题：防止在模型中包含过多的字段用于记住特定的模式，从而使其更灵活。 以量化方式进行度量可能有难度，但如果可以删除特征并保持相同的准确度，则有可能会使模型变得更灵活，并降低过度拟合的风险。

## <a name="best-practices-automated-ml-implements"></a>自动化 ML 实现的最佳实践

### <a name="regularization-and-hyperparameter-tuning"></a>正则化和超参数优化

正则化是最大程度地减小代价函数来惩罚复杂的过度拟合模型的过程。 正则化函数的类型各不相同，但通常它们都会对模型系数的大小、方差和复杂性进行惩罚。 自动化 ML 结合用于控制过度拟合的不同模型超参数设置，使用 L1 (Lasso)、L2 (Ridge) 和 ElasticNet（同时包括 L1 和 L2）的不同组合。 简单而言，自动化 ML 会改变模型的管控程度，并选择最佳结果。

### <a name="model-complexity-limitations"></a>模型复杂性限制

自动化 ML 还实施明确的模型复杂性限制来防止过度拟合。 在大多数情况下，此实现专用于决策树或林算法，其中每个树的最大深度受到限制，并且在林或组合学习方法中使用的树总数也受到限制。

### <a name="cross-validation"></a>交叉验证

交叉验证 (CV) 是从完整定型数据提取许多子集并针对每个子集定型一个模型的过程。 其思路是，针对某个子集时，模型可能会“幸运地”具有高准确度，但在使用多个子集时，模型不会每次都实现这种高准确度。 执行 CV 时，需要提供一个验证维持数据集，指定 CV 折数（子集数），然后，自动化 ML 将训练模型并优化超参数，以尽量减少验证集的错误。 可能有一个 CV 折过度拟合，但如果使用许多的折，则可以减少最终模型过度拟合的可能性。 缺点是 CV 会导致训练时间变得更长，从而增大成本，因为模型不是训练一次，而是针对 *n* 个 CV 子集中的每个子集训练一次。 

> [!NOTE]
> 默认情况下不启用交叉验证；它必须在自动化 ML 设置中进行配置。 但是，在配置交叉验证并提供验证数据集后，此过程将自动执行。 详细了解[自动化 ML 中的交叉验证配置](how-to-configure-cross-validation-data-splits.md)

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>标识具有不均衡数据的模型

不均衡数据通常存在于机器学习分类场景的数据中，它是指在每个类中包含比例不相称的观察值的数据。 这种不平衡可能会对模型准确度造成错误的认知效应，因为输入数据与一个类存在偏差，从而导致训练的模型模拟该偏差。 

此外，自动化 ML 运行会自动生成以下图表，以帮助你了解模型分类的正确性，并识别可能受到不平衡数据影响的模型。

图表| 说明
---|---
[混淆矩阵](how-to-understand-automated-ml.md#confusion-matrix)| 根据数据的实际标签评估正确分类的标签。 
[精准率-召回率](how-to-understand-automated-ml.md#precision-recall-curve)| 根据发现的数据标签实例比评估正确的标签比 
[ROC 曲线](how-to-understand-automated-ml.md#roc-curve)| 根据误报标签比评估正确的标签比。

## <a name="handle-imbalanced-data"></a>处理不平衡的数据 

自动化 ML 可以通过其内置功能来帮助处理不平衡的数据，以实现其简化机器学习工作流的目标，例如： 

- **权重列**：自动化 ML 支持将权重列用作输入，以便能够增大或减小数据中的行的权重，权重可用于使某个类的“重要性”更大或更小。

- 当少数类中的样本数等于或少于多数类中的样本数的 20% 时（其中少数类是指样本最少的类，多数类是指样本最多的类），自动化 ML 使用的算法会检测到不均衡现象。 然后，AutoML 会使用子采样的数据运行试验，以检查使用类权重是否可以纠正此问题并提高性能。 如果通过此试验确定性能得到提高，则采用此补救措施。

- 使用性能指标来更好地处理不平衡的数据。 例如，AUC_weighted 是一项主要指标，它基于表示每个类的样本的相对数量计算该类的贡献，因此能够更可靠地应对不平衡。

以下技术是用于处理自动化 ML 外部的不平衡数据的附加选项。 

- 通过向上采样较小的类或向下采样较大的类，重新采样来均衡类的不平衡性。 这些方法需要具备处理和分析方面的专业知识。

- 查看不平衡数据的性能指标。 例如，F1 分数是查准率和查全率的调和平均值。 查准率用于度量分类器的准确度，查准率越高表示误报越少，而查全率则用于度量分类器的完整性，查全率越高表示误报越少。

## <a name="next-steps"></a>后续步骤

查看示例并了解如何使用自动化机器学习生成模型：

+ 按照[教程：使用 Azure 机器学习自动训练回归模型](tutorial-auto-train-models.md)

+ 为自动训练实验配置设置：
  + 在 Azure 机器学习工作室中[使用这些步骤](how-to-use-automated-ml-for-ml-models.md)。
  + 通过 Python SDK，[使用这些步骤](how-to-configure-auto-train.md)。
